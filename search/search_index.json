{"config":{"lang":["en"],"separator":"[\\s\\-\\_]","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":"Ready to read?"},{"location":"index.html#whats-new","title":"What's new?","text":"<p>PLEASE NOTE THIS REPOSITORY IS UNDER CONSTRUCTION, WE WILL COMMUNICATE ONCE OFFICIALLY OPENED</p>"},{"location":"index.html#presentation","title":"Presentation","text":"<p>Juniper Networks and HPE Networking are introducing a new concept of online technical books dedicated to networking. This documentation will be available both online and in PDF format, providing in-depth insights into Juniper technologies and best practices. The books will be continuously updated to reflect the latest advancements, ensuring that readers always have access to the most current information.</p> <p>Enjoy reading...</p>"},{"location":"index.html#audience","title":"Audience","text":"<p>This site is aimed at technical professionals who want to explore or enhance their skills in networking, protocols, observability, and automation.</p>"},{"location":"about.html","title":"About us","text":"<p>This portal is maintained by Juniper Network / HPE employees. </p> <p>You can use GitHub issues to provide feedback, report content errors, or suggest improvements.</p> <p>Thanks.</p>"},{"location":"build.html","title":"Under construction","text":"<p>Sorry... Come back later...</p>"},{"location":"download.html","title":"Download Street","text":"<p>This is the place to download all our contents in PDF.</p> <p></p>"},{"location":"books/menu/main.html","title":"Select a book","text":"Sample book Sub-Title of the book"},{"location":"books/sample_book/main.html","title":"Goal of this Article","text":"<p>/!\\ This is a copy of an existing Techpost just for illustration purposes </p> <p>This article provides a detailed overview of Filter-Based Forwarding (FBF), also known as Policy-Based Routing (PBR), on MX Series routers (AFT), using common deployment scenarios to illustrate configuration methods.  </p> <p>The Filter-Based Forwarding (FBF) concept is relatively simple. On ingress, filtering (via the Firewall Filter toolkit) is applied before the the source or destination route lookup. The diagram below illustrates this process. In a standard routing scenario without any constraints, the destination IP from the IP datagram is used for a rou te lookup (using Longest Prefix Match<sup>1</sup>), which returns a next-hop and an associated egress interface. (Encapsulation may occur prior to egress.)</p> <p>With FBF, we alter the ingress lookup behavior in one of the following ways:</p> <ul> <li>Forcing traffic to exit through a specific egress port;</li> <li>Using a \"proxy\" or alias IP address as the lookup key (as shown in our example below);</li> <li>Leveraging a specific, constrained forwarding instance to influence the lookup outcome.</li> </ul> <p></p> <p>To summarize, on Juniper platforms, FBF can generally be implemented using two main approaches. The first is more straightforward and involves minimal configuration, but offers limited flexibility. It uses a single firewall filter to directly redirect traffic. The second approach requires slightly more configuration but offers more granular traffic handling.</p> <p>All examples are based on Junos OS release 24.2. We\u2019ll begin with the simpler method.</p>"},{"location":"books/sample_book/main.html#case-1-fbf-using-next-ip-next-interface-actions","title":"Case 1 - FBF Using next-ip / next-interface Actions","text":"<p>RLI 14784 introduces two new terminating actions in firewall filters:</p> <ul> <li>next-interface  routing-instance  <li>next-ip  routing-instance  <p>Note: IPv6 is also supported via the <code>next-ip6</code> variant.</p> <p>These actions are terminating, meaning there's no need to include an explicit <code>accept</code> statement. Both are supported under the <code>inet</code> and <code>inet6</code> families.</p> <p>The typical usage for these actions is illustrated below:</p> <pre><code>firewall {\n    family inet|inet6 {\n      filter foo {\n        from { \n          Any from the set of ip match conditions\n        } then {\n          next-interface &lt;intf-name&gt; routing-instance &lt;RI-name&gt;\n      }\n    }\n  }\n\n  family inet {\n      filter foo4 {\n        from { \n          Any from the set of ipv4 match conditions\n        } then {\n          next-ip &lt;prefix&gt; routing-instance &lt;RI-name&gt;\n      }\n    }\n  }\n\n  family inet6 {\n      filter foo6 {\n        from { \n          Any from the set of ipv6 match conditions\n        } then {\n          next-ip6 &lt;prefix&gt; routing-instance &lt;RI-name&gt;\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"books/sample_book/main.html#overall-behavior","title":"Overall Behavior","text":"<p>When a packet matches a term using one of the below actions:</p> <ul> <li><code>next-interface</code>: The system verifies the operational state of the specified interface, along with the availability of an ARP (or ND for IPv6) entry for the next-hop. If a <code>routing-instance</code> is specified, the interface lookup is performed within that context. If all conditions are met, the packet is forwarded via the corresponding egress IFL. If the interface is down or unresolved, the packet is dropped.</li> <li><code>next-ip(6)</code>: The IP address specified in <code>next-ip</code> or <code>next-ip6</code> is not automatically resolved. On Ethernet interfaces, reachability must be ensured through routing\u2014either via dynamic protocols or static routes. If a matching route (exact or more specific) is found, the packet follows the next-hop associated with that route. If no matching route exists, the packet is rejected.</li> </ul> <p>Read carefully: if next-ip address becomes unreachable the default approch is to point the traffic to the default reject next-hop. Traffic rejected are thus punted to the RE for sending back an ICMP unreachable. However, no worries about \"overloading\" the internal host-path. Indeed, there is a default DDOS protection policer that will rate-limit those rejected punted packets to 2Kpps. We will see later, how to handle this behavior in case you want silencly discard the packet when next-ip address becomes unreachable. </p>"},{"location":"books/sample_book/main.html#caveats","title":"Caveats","text":"<p>Known limitations include:</p> <ul> <li>Supported only for ingress filtering</li> <li>No fallback mechanism (The EVO exact match option is not supported)</li> <li>Not supported on LT interfaces</li> </ul>"},{"location":"books/sample_book/main.html#example-1-topology","title":"Example 1 - topology","text":"<p>The diagram below illustrates the topology used to demonstrate simple FBF on an MX platform. The Device Under Test (DUT) is an MX480 equipped with an MPC10E line card.</p> <p>This simplified setup represents a typical DCI router connected to an IP Fabric, providing access to remote resources via two distinct paths:</p> <ul> <li>A quality path through an MPLS/SR core network, and</li> <li>A best-effort path via a direct peering or transit (PNI) connection.</li> </ul> <p>By default, remote resources are reached via the direct PNI link. The DUT hosts an Internet VRF, which is also used by a remote ASBR in the same AS. This ASBR advertises \"public/remote\" prefixes to all PE routers\u2014including the DUT\u2014via L3VPN (inet-vpn). The direct PNI interface is also part of the Internet VRF.</p> <p></p> <p>For demonstration purposes, the remote resource is simulated using the public prefix 8.8.8.0/24. This prefix is preferred by default via the direct PNI, with a backup path available through the MPLS/SR core:</p> <pre><code>regress@rtme-mx-62&gt; show route 8.8.8.0/24 \n\nVRF1.inet.0: 9 destinations, 13 routes (9 active, 0 holddown, 0 hidden)\n+ = Active Route, - = Last Active, * = Both\n\n8.8.8.0/24         *[BGP/170] 00:00:04, localpref 10000\n                      AS path: 1234 6000 I, validation-state: unverified\n                    &gt;  to 172.16.8.1 via et-2/0/0.0                             &lt;&lt;&lt; Via PNI\n                    [BGP/170] 21:23:18, localpref 100, from 193.252.102.201\n                      AS path: I, validation-state: unverified\n                    &gt;  to 172.16.1.1 via et-5/0/0.0, Push 16, Push 20103(top)   &lt;&lt;&lt; Via MPLS/SR Core\n</code></pre> <p>The IP Fabric serves two customer types\u2014A and B\u2014represented by IP prefixes 172.111.0.0/24 and 172.222.0.0/24, respectively. The DUT exchanges IP traffic with these customers directly.</p> <p>Initial Configuration</p> <p>Below is the initial configuration for the DUT's Internet VRF, kept simple for clarity:</p> <ul> <li>The DUT receives customer prefixes via eBGP from the peer group FABRIC.</li> <li>It receives public prefixes from the peer ASBR via eBGP, with an import policy (PREF) setting a high local preference to make this path the best.</li> <li>Two interfaces belong to the Internet VRF\u2014one facing the IP Fabric, and the other towards the PNI peer.</li> <li>The DUT also connects to the MPLS core, running IS-IS with Segment Routing for label distribution.</li> </ul> <pre><code>regress@rtme-mx-62&gt; show configuration routing-instances VRF1 \ninstance-type vrf;\nprotocols {\n    bgp {\n        group FABRIC {\n            type external;\n            local-address 172.16.0.4;\n            peer-as 5000;\n            neighbor 172.16.0.5;\n        }\n        group PEER {\n            type external;\n            local-address 172.16.8.0;\n            import PREF;\n            family inet {\n                unicast;\n            }\n            peer-as 1234;\n            neighbor 172.16.8.1;\n        }\n    }\n}\ninterface et-4/0/0.0;\ninterface et-5/2/0.100;\nroute-distinguisher 193.252.102.101:1;\nvrf-target target:65000:1234;\nvrf-table-label;\n</code></pre> <p>Configuration of FBF</p> <p>Using the previous topology, we demonstrate a typical FBF use case leveraging the <code>next-ip</code> action (the same behavior applies to <code>next-ip6</code> and <code>next-interface</code>).</p> <p>The objective is to override the default forwarding behavior\u2014where traffic exits via the direct PNI interface\u2014for traffic sourced from Customer B (172.222.0.0/24). Instead, traffic from this prefix should be redirected through the MPLS backbone, targeting the remote ASBR to reach the public resource.</p> <p>Traffic from other sources will continue to follow the default \u201cbest path,\u201d which remains the direct PNI link.</p> <p>The diagram below illustrates this behavior:</p> <p></p> <p>How will we achieve this?</p> <p>The configuration is straightforward. First, we define a firewall filter that matches the source prefix 172.222.0.0/24, and apply the <code>next-ip</code> action to redirect traffic.</p> <p>Which <code>next-ip</code> address should be used? That depends on the network design. In this example, we target the loopback address of the remote ASBR, which is advertised via BGP (L3VPN). As shown below, the route to this loopback is reachable through the MPLS/SR core via an established tunnel:</p> <pre><code>regress@rtme-mx-62&gt; show route 192.168.1.1 table VRF1.inet   \n\nVRF1.inet.0: 9 destinations, 13 routes (9 active, 0 holddown, 0 hidden)\n+ = Active Route, - = Last Active, * = Both\n\n192.168.1.1/32     *[BGP/170] 20:42:26, localpref 100, from 193.252.102.201\n                      AS path: I, validation-state: unverified\n                    &gt;  to 172.16.1.1 via et-5/0/0.0, Push 16, Push 20103(top)\n</code></pre> <p>Now let's configure the FBF filter. Since we're operating within a VRF context, the <code>routing-instance</code> parameter is specified along with the <code>next-ip</code> action\u2014this ensures that the next-hop lookup is performed in the correct FIB instance.</p> <p>An additional term is included to match all remaining traffic, allowing it to follow the default forwarding behavior.</p> <pre><code>family inet {\n    filter FBF {\n        term PBR_CUSTOMER_B {\n            from {\n                source-address {\n                    172.222.0.0/24;\n                }\n            }\n            then {\n                count CUSTOMERB;\n                next-ip 192.168.1.1/32 routing-instance VRF1;\n            }\n        }\n        term OTHER {\n            then {\n                count OTHER;\n                accept;\n            }\n        }\n    }\n}\n</code></pre> <p>Before applying the filter, we'll generate traffic from Customer A and Customer B. To distinguish between the two flows, we configure the traffic rates as follows:</p> <ul> <li>Customer A: 1000 packets per second (pps)</li> <li>Customer B: 5000 packets per second (pps)</li> </ul> <p>Both customers will send traffic toward the 8.8.8.0/24 prefix.</p> <p>We now start the traffic and verify the statistics on the PNI interface:</p> <pre><code>regress@rtme-mx-62&gt; monitor interface et-2/0/0.0   \n\n&lt;- truncated output -&gt;\n\nRemote statistics:\n  Input bytes:                 132708516 (0 bps)                           [0]\n  Output bytes:              48292808336 (23518344 bps)             [11195520]\n  Input packets:                  270844 (0 pps)                           [0]\n  Output packets:               98556757 (6000 pps)                    [22848] &lt;&lt;&lt; Customer A + Customer B traffics\n</code></pre> <p>At this point, all traffic is following the best active path\u2014via the PNI interface\u2014to reach the 8.8.8.0/24 prefix.</p> <p>We now apply the FBF filter in the ingress direction on the interface connected to the IP Fabric:</p> <pre><code>edit private\n\nset interfaces et-5/2/0 unit 100 family inet filter input FBF\n\ncommit comment \"ADD_FBF\" and-quit\n</code></pre> <p>And then, recheck the PNI interface statistics: </p> <pre><code>regress@rtme-mx-62&gt; monitor interface et-2/0/0.0   \nInterface: et-2/0/0.0, Enabled, Link is Up\n\n&lt;- truncated output -&gt;\n\nRemote statistics:\n  Input bytes:                 132708516 (0 bps)                           [0]\n  Output bytes:              49128737556 (3921056 bps)                     [0]\n  Input packets:                  270844 (0 pps)                           [0]\n  Output packets:              100262735 (1000 pps)                        [0] &lt;&lt;&lt; Only Customer A traffic\n</code></pre> <p>The FBF filter is functioning as expected. Only Customer A traffic continues to follow the default best path toward 8.8.8.0/24 via the PNI interface.</p> <p>Next, we check the statistics on the core-facing interfaces to confirm that Customer B traffic is being properly redirected through the SR/MPLS tunnel as intended by the FBF configuration:</p> <pre><code>regress@rtme-mx-62&gt; monitor interface et-5/0/0.0  \nInterface: et-5/0/0.0, Enabled, Link is Up\n\n&lt;- truncated output -&gt;\n\nRemote statistics:\n  Input bytes:                 253750639 (584 bps)                         [0]\n  Output bytes:              57241664165 (19600072 bps)                    [0]\n  Input packets:                  533880 (1 pps)                           [0]\n  Output packets:              116839924 (5000 pps)                        [0] &lt;&lt;&lt; the tunneled Customer B traffic \n</code></pre> <p>Everything looks good! To demonstrate that there is no fallback mechanism with next-ip-based FBF, we'll remove the loopback (192.168.1.1/32) announcement from the ASBR. As a result, the DUT will no longer have a route to the loopback, and the traffic will be dropped:</p> <pre><code>regress@rtme-mx-62&gt; show route 192.168.1.1 table VRF1.inet   \n</code></pre> <p>This means that traffic from Customer B should be dropped, which is exactly what we observe. As shown below, there is no longer any traffic on the Core interface, and Customer A traffic continues to flow through the PNI port.</p> <pre><code>regress@rtme-mx-62&gt; monitor interface et-5/0/0.0  \nInterface: et-5/0/0.0, Enabled, Link is Up\n\n&lt;- truncated output -&gt;\n\nRemote statistics:\n  Input bytes:                 253763429 (248 bps)                         [0]\n  Output bytes:              58533097602 (0 bps)                          [57]\n  Input packets:                  534091 (0 pps)                           [0]\n  Output packets:              119475689 (0 pps)                           [1] &lt;&lt;&lt; Customer B traffic dropped\n\nmonitor interface et-2/0/0.0 \nInterface: et-2/0/0.0, Enabled, Link is Up\n\n&lt;- truncated output -&gt;\n\nRemote statistics:\n  Input bytes:                 132708516 (296 bps)                         [0]\n  Output bytes:              49685006066 (3921096 bps)                     [0]\n  Input packets:                  270844 (0 pps)                           [0]\n  Output packets:              101397976 (1000 pps)                        [0] &lt;&lt;&lt; Customer A still forwarded\n</code></pre> <p>As discussed earlier, the default action when next-ip address becomes unreachable is to redirect traffic to the reject next-hop. Above, we issue a show route of the next-ip address and nothing was return as expected. Just now issue the show route forwarding-table:</p> <pre><code>regress@rtme-mx-62&gt; show route forwarding-table destination 192.168.1.1 table VRF1    \nRouting table: VRF1.inet\nInternet:\nDestination        Type RtRef Next hop           Type Index    NhRef Netif\ndefault            perm     0                    rjct      695     1       &lt;&lt;&lt; rjct = reject next-hop\n</code></pre> <p>The route points to reject next-hop in the FIB. As said, the next-hop will punted the packets to the RE for further processing (ICMP unreachable). As also mentioned those punted packet are rate-limited by the ASIC to 2kpps. We can verify this behavior, by checking the DDOS protection statistics for the \"reject\" protocol:</p> <pre><code>regress@rtme-mx-62&gt; show ddos-protection protocols reject statistics terse \nPacket types: 1, Received traffic: 1, Currently violated: 1\n\nProtocol    Packet      Received        Dropped        Rate     Violation State\ngroup       type        (packets)       (packets)      (pps)    counts\nreject      aggregate   6396663340756   6395549305435  5000     9         viol \n</code></pre> <p>We saw our 5K of Customer B traffic before being rate-limited. Issue the \"violation\" check command to see the rate-limit value of 2K pps: </p> <pre><code>regress@rtme-mx-62&gt; show ddos-protection protocols violations \nPacket types: 255, Currently violated: 1\n\nProtocol    Packet      Bandwidth  Arrival   Peak      Policer bandwidth\ngroup       type        (pps)      rate(pps) rate(pps) violation detected at\nreject      aggregate   2000       5000      11682678  2025-04-10 08:22:39 PDT  &lt;&lt;&lt; Bandwidth = rate-limit = 2k pps\n          Detected on: FPC-5\n</code></pre> <p>So it means our RE will received a maximum of 2K rejected packets and will generate 2K ICMP unreachable packets in reply. Just check our port connected to the IP Fabric and oh ! Suprise 2Kpps in output. These are our ICMP unreachable sent out back to the Customer B.</p> <pre><code>regress@rtme-mx-62&gt; monitor interface et-2/0/0.0   \nInterface: et-2/0/0.0, Enabled, Link is Up\n\n&lt;- truncated output -&gt;\n\nRemote statistics:\n  Input bytes:              117022326356 (23519664 bps)             [11197970]\n  Output bytes:                178738122 (895984 bps)                 [426496]\n  Input packets:               238821075 (6000 pps)                    [22853]\n  Output packets:                3191752 (2000 pps)                     [7616] &lt;&lt;&lt; 2K ICMP Unreachable targeting Cust. B\n</code></pre> <p>How we can avoid that? </p> <p>The easiest solution is to have in your FIB always a last resort route entry, that could be discard but why not a fallback path to route the next-ip address. In our case, if 192.168.1.1 deaseappers, we may want:</p> <ul> <li>to not reject/discard the traffic but move back to the PNI interface. For that we need to configure a static route pointing to PNI peer, with a higher preference as a backup path for 192.168.1.1. Let's do simply add this static route in our VRF and check just after the commit the statistics of our PNI interface to see if all our 6K pps (A+B traffic) are forwarded back:</li> </ul> <pre><code>edit private\n\nset routing-instances VRF1 routing-options static route 192.168.1.1/32 next-hop 172.16.8.1 preference 254\n\ncommit comment \"ADD_BACKUP_NEXT_IP\" and-quit\n\nregress@rtme-mx-62&gt; monitor interface et-2/0/0.0   \nInterface: et-2/0/0.0, Enabled, Link is Up\n\n&lt;- truncated output -&gt;\n\nRemote statistics:\n  Input bytes:                 132708516 (0 bps)                           [0]\n  Output bytes:              50812435866 (23522568 bps)              [5629120]\n  Input packets:                  270844 (0 pps)                           [0]\n  Output packets:              103698854 (6000 pps)                    [11488] &lt;&lt;&lt; We backup B traffic to PNI\n</code></pre> <ul> <li>or to silently discard the traffic. In this scenario we can create a static route with higher preference pointing to discard next-hop. In our case, I've just added a default discard route in the VRF. so, if 192.168.1.1/32 is not announce anymore, the lookup of the next-ip address will fall back to this default discard instead of matching the default reject. Let's remove the previous static route and add the new default one:</li> </ul> <pre><code>edit private\n\ndelete routing-instances VRF1 routing-options static route 192.168.1.1/32          \nset routing-instances VRF1 routing-options static route 0.0.0.0/0 discard \n\ncommit comment \"ADD_DEFAULT\" and-quit\n</code></pre> <p>So, with this last configuration, our Customer B traffic should be now silently discared and we shouldn't observe DDOS protocol violation and ICMP unreachable traffic:</p> <pre><code>regress@rtme-mx-62&gt; monitor interface et-2/0/0.0   \nInterface: et-2/0/0.0, Enabled, Link is Up\nFlags: SNMP-Traps 0x4000\nEncapsulation: ENET2\nLocal statistics:                                                Current delta\n  Input bytes:                    216186                                   [0]\n  Output bytes:                   505399                                   [0]\n  Input packets:                    3530                                   [0]\n  Output packets:                   6274                                   [0]\nRemote statistics:\n  Input bytes:              119682374166 (23516136 bps)              [5628630]\n  Output bytes:                230359258 (0 bps)                           [0]\n  Input packets:               244249744 (5999 pps)                    [11487]\n  Output packets:                4113558 (0 pps)                           [0] &lt;&lt;&lt; No more ICMP Unreach. \n\n\nregress@rtme-mx-62&gt; show ddos-protection protocols violations    \nPacket types: 255, Currently violated: 0   &lt;&lt;&lt; No more Violation \n</code></pre>"},{"location":"books/sample_book/main.html#pfe-analysis","title":"PFE analysis","text":"<p>Now, let\u2019s re-announce the 192.168.1.1/32 prefix and examine how the FBF filter is applied on the PFE. Begin by running the following command to access the PFE CLI:</p> <pre><code>regress@rtme-mx-62&gt; start shell pfe network fpc5\n</code></pre> <p>Next, list all the filters available on the linecard:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show firewall \nName                                   Index          Token            Status\nFBF                                    1               2875            DMEM\n&lt;- truncated output -&gt;\n</code></pre> <p>Now resolve the token index <code>2875</code> to display the filter\u2019s program:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show sandbox token 22571514 \n\n&lt;- truncated output -&gt;\n\nFilter properties: None\nFilter state = CONSISTENT\nterm PBR_CUSTOMER_B\nterm priority 0\n    source-address\n        172.222.0/24\n        false branch to match action in rule OTHER\n\n    then\n        accept\n        count CUSTOMERB\n         Policy Route:\n         Destination Prefix: 192.168.1.1\n         Routing instance: VRF1\n         Policy route action is valid: TRUE\nterm OTHER\nterm priority 0\n\n    then\n        accept\n        count OTHER\nPrevious nodes count: 1      \nNext nodes count    : 0      \nEntries count       : 0               \n</code></pre> <p>The above output shows the filter program optimized by the Firewall Filter compiler. To display the actual program pushed into hardware, use the following PFE commands:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show firewall instance \nName,Index              Instance Key                    InstanceToken           LinkCount\nFBF,1                   no-next-filter-0                5424                    1\n&lt;- truncated output -&gt;\n</code></pre> <p>Then, run this second command using the Token ID <code>5424</code>, retrieved from the previous step:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show sandbox token 5424 \n\n&lt;- truncated output -&gt;\n\nJNH_FW_START:\n        opcode = 0x0000000c\n        anonymous_union_0 = 0x00008605\n        filter_id = 0x00000000\n        cntr_base = 0x00000001\n        flt_base = 0x00000000\n        base_ptr = 0x000255af\n\nFilter is not interface specific 1\n\nCurrent context : 0.\n\nPfe Inst:0 Hw Instance 1, type:1 op:2 ref 0\n  Counter Base:- 0x5400f8\n  Policer Base:- 0\n  Number of counters : 2 (including PSAs)\n\nterm PBR_CUSTOMER_B (pfe-inst 0)\n     Start Addr   :- 0x8605\n     Stop Addr    :- 0x8607\n     Stop NH      :- 0x6808255ab012ad58\n         Decoding :- FW_STOP: pdesc:0x104ab56 desc:0x4ab56\n\n     Action Addr  :- 0x4ab56\n     Action NH    :- 0x812aed800010000\n\nmatch type: prefix\n  loc: 0x8605 nh: 0x7e30004002800000\n  FW_4BMATCH: fwop:0 desc:0x8005 koffset:396 boffset:0 mask:0x149c00e8 data:0x7fb7\n\nInst: 0 Action-Type: 134\n        JNH      :- 0x2bfffffd00000300:   &lt;&lt;&lt; count CUSTOMERB;\n                 CounterNH: Relative Base = 1, Offset = 0x0, nextNH = 0xffffff\n\nInst: 0 Action-Type: 0\n        JNH      :- 0x201282240000000c:   &lt;&lt;&lt; next-ip 192.168.1.1/32 routing-instance VRF1;\n                 UcodeNH: Indirect Decode: Indirect, Next = 0x4a089, pnh_id = 0, ,\n\n&lt;- truncated output -&gt;\n</code></pre> <p>Pick the JNH dword corresponding to the next-ip action <code>0x201282240000000c</code> (line 40), and decode it:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x201282240000000c inst 2    \nUcodeNH: Indirect Decode: Indirect, Next = 0x4a089, pnh_id = 0,\n</code></pre> <p>UcodeNH will run a micro-code sequence. Here, it is an indirection to a virtual address found in the Next field. To read the data at <code>0x4a089</code>, run:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh vread vaddr 0x4a089 NH inst 2            \nAddr:Nexthop 0x4a089 Paddr:0x104a089, Data = 0x0812659400040000\n</code></pre> <p>This returns two key values:</p> <ul> <li>Paddr (physical address): <code>0x104a089</code></li> <li>Data read: <code>0x0812659400040000</code></li> </ul> <p>Note: To read a physical address, use <code>show pread paddr xxx</code>.</p> <p>Since the value is a JNH word, decode it again. This time it reveals a CallNH, a list of ordered next-hops (when mode=0):</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x0812659400040000 inst 2 \nCallNH:desc_ptr:0x49965, mode=0, count=0x5\n  0x049960  0 : 0x168c000000000000\n  0x049961  1 : 0x40101ffffff81510\n  0x049962  2 : 0x40181fffffe02030\n  0x049963  3 : 0x1810318200200008\n  0x049964  4 : 0x23fffffc00000001 &lt;&lt;&lt; this one will be skipped - related to fabric encap.\n</code></pre> <p>Now decode each action (excluding the fifth one, which is outside the scope of this article):</p> <ul> <li>The first is a <code>ModifyNH</code>, which modifies local memory \u2014 in this case, resetting the encapsulation length:</li> </ul> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x168c000000000000 inst 2    \nModifyNH: Subcode=Misc(26)\n(Reset encap len)\n</code></pre> <ul> <li>The second and third entries are BitOpNH actions, performing operations on specific data:</li> </ul> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x40101ffffff81510 inst 2    \nBitOpNH: opcode=0x00000008, data32=0, desc_ptr=0xffffff, key=0x4/0 PPPoE Session ID, op=0, data=49320, nbits=16\n\nroot@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x40181fffffe02030 inst 2    \nBitOpNH: opcode=0x00000008, data32=0, desc_ptr=0xffffff, key=0x6/0 Unknown, op=0, data=257, nbits=16\n</code></pre> <p>These actions extract the next-ip address from local memory in two steps:</p> <ul> <li>First, we fetch <code>49320</code> (0xC0A8 = 192.168)</li> <li>Then, we fetch <code>257</code> (0x0101 = 1.1)</li> </ul> <p>Combined, we recover the next-ip address from our FBF filter: 192.168.1.1. This is a \"key\" that will be used for further processing (route lookup).</p> <ul> <li>The fourth NH in the list <code>0x1810318200200008</code> is a KTREE structure used for route lookup:</li> </ul> <p>A KTREE is Juniper\u2019s implementation of a binary structure known as a Patricia Tree.</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x1810318200200008 inst 2    \nKtreeNH: skip=8, sw_token=0, arOffset=0, mode=1, descPtr=0xc60800, key=0x4/0 LookupKey\n</code></pre> <p>To dump the full KTREE, use:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x1810318200200008 inst 2 ktree yes dump yes \nRoute                                 Depth   JNH\n------------------------------------  ------  ------------------\nDefault                                    0  0x0812ad6000000000\n00000000/32                                1  0x0812a08400000000\n080808/24                                  1  0x08129d0400000000\nacde00/24                                  2  0x08129df400000000\nac6f00/24                                  2  0x08129df400000000\nac100800/31                                3  0x000000000004ab3c\nac100801/32                                4  0x0812ade000000000\nac100800/32                                4  0x0812ac9800010000\nac100004/31                                3  0x000000000004abc0\nac100005/32                                4  0x08129d4800000000\nac100004/32                                4  0x0812aec800010000\nc0a80101/32                                1  0x08129a1800000000 &lt;&lt;&lt; 192.168.1.1/32\ne0000001/32                                1  0x0812a0c400000000\nffffffff/32                                1  0x0812a0e400000000\n\nRoutes found: 14, Bytes used: 6664\n</code></pre> <p>This KTREE acts as the FIB for our VRF1 instance. For instance, traffic hitting the 192.168.1.1/32 prefix is redirected to the action identified by the JNH word <code>0x08129a1800000000</code>, pointing to a CallNH:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x08129a1800000000 inst 2    \nCallNH:desc_ptr:0x4a686, mode=0, count=0x1\n  0x04a685  0 : 0x20129af00000000c\n</code></pre> <p>This value (<code>0x20129af00000000c</code>) is another UcodeNH indirection:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x20129af00000000c inst 2    \nUcodeNH: Indirect Decode: Indirect, Next = 0x4a6bc, pnh_id = 0, ,\n</code></pre> <p>To follow the indirection, read the next-hop at <code>0x4a6bc</code>:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh vread vaddr 0x4a6bc NH inst 2            \nAddr:Nexthop 0x4a6bc Paddr:0x104a6bc, Data = 0x08129ad400000000\n</code></pre> <p>Once again, decode the JNH word retrieved from the virtual memory address \u2014 it points to another CallNH list:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x08129ad400000000 inst 2    \nCallNH:desc_ptr:0x4a6b5, mode=0, count=0x1\n  0x04a6b4  0 : 0x11c0000000026c14\n</code></pre> <p>Decode the final NH word <code>0x11c0000000026c14</code>:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x11c0000000026c14 inst 2    \nModifyNH: Subcode=SetNH-Token(7),Desc=0x0,Data=0x26c14,NextNH=0\n (pfeDest:20, TokenIdMode:0/  , VC memberId:0, isReass:0, token:0x26c/620)\n</code></pre> <p>We\u2019ve reached the final forwarding action \u2014 setting the forwarding NH index via the NH Token. Here, the token <code>0x26c</code> corresponds to the NH ID from our route lookup.</p> <p>To get more info on this next-hop:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show nh db index 0x26c                                   \nIndex          Type        Func-Type    Proto        Nh-Flags        Ifl-Name        Ifl-Index       Nh-Token        Nh-Prefix\n620            Unicast     -            ipv4_tag     0x41            et-5/0/0.0      356             5519           ac100101/32                                   \n</code></pre> <p>Perfect \u2014 this confirms that the traffic is forwarded via the correct path: our core-facing interface <code>et-5/0/0.0</code> and doesn't follow anymore the \"best path\".</p> <p>To go further (e.g., check Layer 2 headers or MPLS encapsulation), use:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show nh detail index 0x26c     \nNexthop Info:\n\nNH Index                      : 620\nNH Type                       : Unicast\nNH Proto                      : ipv4_tag\nNH Flags                      : 0x41\nIF Name                       : et-5/0/0.0\nPrefix                        : ac100101/32\nNH Token Id                   : 5519\nNH Route Table Id             : 0\nSgid                          : 0\n\nOIF Index                     : 356\nUnderlying IFL                : .local..0 (0)\nSession Id                    : 788\nNum Tags                      : 2\nLabel                         : 0x4e87eff0 (20103)lbFlags: 0\nLabel                         : 0x10fff000 (16)lbFlags: 0\nMTU                           : 0\nL2 Length                     : 12\nL2 Data                       : 00:00:01:64:80:00:a8:d0:e5:ef:6a:87\nFilter Index                  : 0\n\nPlatform Info\n-------------\n  FabricToken: 5527\n  EgressToken: 5526\n  IngressFeatures:\n\nContainer token: 5519\n#5 SetNhToken tokens:\n Mask : 0x0\n [  SetNhToken:5518  ]\n\n  EgressFeatures:\n\nContainer token: 5526\n#2 PushLabels tokens:\n Mask : 0x0\n [  PushLabels:5522  Token-1:5520  Token-2:5521  ]\n#4 StatsCounter tokens:\n Mask : 0x1\n [  StatsCounter:5523  ]\n#11 UcastEncap tokens:\n Mask : 0x0\n [  UcastEncap:5524  ]\n#12 SetOIF tokens:\n Mask : 0x0\n [  SetOIF:5525  ]\n</code></pre> <p>The figure below summarizes our packet walkthrough and highlights the main FBF steps:</p> <p></p> <p>And that wraps up part one. Take a break \u2014 in part two, we\u2019ll dive into configuring FBF thanks to the rib-group feature.</p>"},{"location":"books/sample_book/main.html#case-2-fbf-using-forwarding-instance","title":"Case 2 - FBF Using forwarding instance","text":"<p>The second approach to achieving Filter-Based Forwarding (FBF) leverages the forwarding-type routing instance. In this method, the FBF filter term action redirects traffic to a specific routing instance of type <code>forwarding</code>.</p> <p>This solution is considered the legacy approach and is widely supported on MX platforms. Compared to Case 1, it requires a deeper understanding of the <code>rib-group</code> concept. The following section will elucidate the necessary concepts to effectively implement FBF using this method.</p>"},{"location":"books/sample_book/main.html#rib-group-concept","title":"rib-group Concept","text":"<p>A RIB group on Juniper devices enables routes learned in one routing table (the source or initial RIB) to be simultaneously installed into multiple routing tables (the destination RIBs). This feature is commonly utilized to share routes between routing instances (VRFs) or between the global routing table and a VRF. Policies can control which routes are imported, making RIB groups a flexible method for internal route redistribution without relying on BGP or other protocols.</p> <p>Without a RIB group, each protocol \u2014 depending on the address family \u2014 feeds routes into a default routing table. In the context of RIB groups, this default table is referred to as the source or initial RIB. Similarly, protocols fetch routes (for a given family) from this default table when exporting routes.</p> <p>The figure below illustrates the default routing behavior:</p> <p></p> <p>As shown above, for BGP with the <code>inet</code> family (IPv4 unicast), the default routing table in the global context is <code>inet.0</code> \u2014 both for importing and exporting routes. Similarly, interface IPv4 addresses (direct routes) in the global context also reside in <code>inet.0</code>.</p> <p>To leak routes from one table to another, the RIB group feature is employed, configured under <code>routing-options</code>. A RIB group is defined with the following parameters:</p> <pre><code>[edit routing-options]\nrib-groups {\n    &lt;rib-group-name&gt; {\n        import-rib [ &lt;source_table&gt; &lt;destination_table_1&gt; &lt;destination_table_2&gt; ... ];\n        import-policy &lt;rib-group-import-policy&gt;;\n        export-policy &lt;rib-group-export-policy&gt;;\n    }\n}\n</code></pre> <p>Note: <code>import-policy</code> and <code>export-policy</code> are optional, but at least one destination table must be specified in <code>import-rib</code>.</p> <p>The <code>import-rib</code> statement is crucial. The order of tables matters: the first table is the source (or initial, standard, contributing) table. This is the default RIB associated with a given protocol/family combination. With a RIB group, routes are taken from this source table and replicated into one or more destination tables.</p> <p>The RIB group establishes a link between the source RIB and the destination RIBs. The <code>import-policy</code> provides fine-grained control, allowing only specific routes or protocols to be leaked to the destination tables. Similarly, <code>export-policy</code> controls which routes from the destination tables are eligible for export by routing protocols.</p> <p>The next figure illustrates the concept:</p> <p></p> <p>This example demonstrates how BGP unicast routes from the global routing context are leaked into a new routing table (or instance) called FBF. While these routes remain in their default (source) table \u2014 <code>inet.0</code> \u2014 they are also copied into an additional table, in this case, the destination <code>FBF.inet.0</code>, using a RIB group.</p> <p>In the context of Filter-Based Forwarding (FBF), this allows you to constrain routing decisions to a specific set of routes \u2014 not by using the standard FIB, but by relying on a custom FIB built from the custom destination RIB. This destination RIB can be selectively populated with only the routes you want to use for FBF-based traffic steering.</p> <p>Let's illustrate this second FBF method with an example.</p>"},{"location":"books/sample_book/main.html#example-2-topology","title":"Example 2 - Topology","text":"<p>The Device Under Test (DUT) is an MX480 equipped with an MPC10E line card.</p> <p>This simplified setup represents a typical DCI router connected to an IP Fabric, providing access to remote resources via two distinct paths:</p> <ul> <li>A quality path through an MPLS/SR core network, and</li> <li>A best-effort path via a direct peering or transit (PNI) connection.</li> </ul> <p>In this scenario, remote resources are reached via the direct PNI link connected in the Global Routing Table (GRT) and sent from the peer to our DUT via an eBGP session. The DUT also receives the same remote resources from a remote ASBR through an iBGP session. The remote ASBR sets the next-hop address of these routes with its Segment Routing node-SID (advertised in the ISIS SR domain). This allows for a BGP Free-core by tunneling traffic in a transport SR tunnel.</p> <p></p> <p>For demonstration purposes, the remote resource is simulated using the public prefix 8.8.8.0/24. This prefix is preferred by default via the direct PNI, with a backup path available through the MPLS/SR core (shortcut SR):</p> <pre><code>regress@rtme-mx-62&gt; show route 8.8.8.0/24 \n\ninet.0: 43 destinations, 44 routes (43 active, 0 holddown, 0 hidden)\n+ = Active Route, - = Last Active, * = Both\n\n8.8.8.0/24         *[BGP/170] 6d 17:31:10, localpref 10000\n                      AS path: 1234 6000 I, validation-state: unverified\n                    &gt;  to 172.16.8.1 via et-2/0/0.0                       &lt;&lt;&lt; PNI\n                    [BGP/170] 00:00:11, localpref 50, from 193.252.102.2\n                      AS path: I, validation-state: unverified\n                    &gt;  to 172.16.1.1 via et-5/0/0.0, Push 20002           &lt;&lt;&lt; SR Tunnel \n</code></pre> <p>Initial Configuration</p> <p>Below is the initial configuration for the DUT, kept simple for clarity:</p> <ul> <li>The DUT receives customer prefixes via eBGP from the peer group FABRIC.</li> <li>The DUT receives public prefixes from the PNI peer\u2014this is the primary/best path. A higher local-preference is set using the <code>PREF</code> import policy.</li> <li>It also receives public prefixes from the peer ASBR via iBGP\u2014this is a backup path\u2014remotely reachable through an MPLS SR Tunnel.</li> </ul> <pre><code>regress@rtme-mx-62&gt; show configuration \nprotocols {\n    bgp {\n        group FABRIC {\n            type external;\n            local-address 172.16.0.4;\n            peer-as 5000;\n            neighbor 172.16.0.5;\n        }\n        group PEER {\n            type external;\n            local-address 172.16.8.0;\n            import PREF;\n            family inet {\n                unicast;\n            }\n            peer-as 1234;\n            neighbor 172.16.8.1;\n        }\n        group ASBR {\n            type internal;\n            local-address 193.252.102.101;\n            family inet {\n                unicast;\n            }\n            neighbor 193.252.102.2;\n        }\n    }\n}\n</code></pre> <p>Configuration of FBF</p> <p>The next steps involve creating a new routing instance (type <code>forwarding</code>) and leaking both the interface routes (i.e., <code>direct</code> routes for resolving the Layer 2 header) and the remote resources (in our case, 8.8.8.0/24), but only those announced by the core network - not those learned via the PNI.</p> <p>First, create the FBF routing instance:</p> <pre><code>edit \nload merge terminal relative\n\nrouting-instances {\n    FBF {\n        instance-type forwarding;\n    }\n}\n\ncommit comment \"add_fbf_ri\"\n</code></pre> <p>Next, create a new <code>rib-group</code> called RG_FBF, establishing a relationship between the <code>inet.0</code> table and <code>FBF.inet.0</code>. In other words, a relation between the default IPv4 table and the IPv4 table of our newly created FBF routing instance.</p> <pre><code>edit \nload merge terminal relative\n\nrouting-options {\n    rib-groups {\n        RG_FBF {\n            import-rib [ inet.0 FBF.inet.0 ];\n        }\n    }\n}\n\ncommit comment \"add_rib-group\"\n</code></pre> <p>Remember, the order inside the <code>import-rib</code> option is important. The first table is considered the source table, and the second one is the destination table. At this point, nothing is leaked between these two tables; this configuration merely establishes the relationship.</p> <p>The first routes to leak are the direct interfaces attached to <code>inet.0</code>. This can be achieved with the following configuration under <code>routing-options</code>:</p> <pre><code>edit \nload merge terminal relative\n\nrouting-options {\n    interface-routes {\n        rib-group inet RG_FBF;\n    }\n}\n\ncommit comment \"import-direct\"\n</code></pre> <p>Once committed, you should see <code>direct</code> and <code>local</code> routes in the <code>FBF.inet.0</code> table. Verify with:</p> <pre><code>regress@rtme-mx-62&gt; show route table FBF.inet.0 \n\nFBF.inet.0: 10 destinations, 10 routes (10 active, 0 holddown, 0 hidden)\n+ = Active Route, - = Last Active, * = Both\n\n172.16.0.4/31      *[Direct/0] 6d 20:12:58\n                    &gt;  via et-5/2/0.0         &lt;&lt;&lt; Fabric\n172.16.0.4/32      *[Local/0] 00:00:59\n                       Local via et-5/2/0.0\n172.16.1.0/31      *[Direct/0] 6d 20:12:58\n                    &gt;  via et-5/0/0.0         &lt;&lt;&lt; Core\n172.16.1.0/32      *[Local/0] 00:00:59\n                       Local via et-5/0/0.0\n172.16.8.0/31      *[Direct/0] 6d 20:12:58\n                    &gt;  via et-2/0/0.0         &lt;&lt;&lt; PNI\n172.16.8.0/32      *[Local/0] 00:00:59\n                       Local via et-2/0/0.0\n193.252.102.101/32 *[Direct/0] 6d 20:12:58\n                    &gt;  via lo0.0\n</code></pre> <p>Everything looks good so far. The next step is to leak some BGP routes into the <code>FBF</code> routing table. But which ones?</p> <p>Our goal is to redirect traffic entering this forwarding instance along a specific path \u2014 the one advertised by our remote ASBR. This route is available in the default <code>inet.0</code> table as a backup path. To achieve this, we'll configure BGP to use the <code>RG_FBF</code> rib-group. This rib-group allows routes normally imported into <code>inet.0</code> to be simultaneously leaked into <code>FBF.inet.0</code>.</p> <p>Let\u2019s apply this on the <code>ASBR</code> peer-group:</p> <pre><code>edit \nedit protocols\nload merge terminal relative\n\nbgp {\n    group ASBR {\n        type internal;\n        local-address 193.252.102.101;  \n        family inet {\n            unicast {\n                rib-group RG_FBF;    &lt;&lt;&lt; This tells BGP to use the rib-group and specifies where to leak learned routes\n            }\n        }\n        neighbor 193.252.102.2;\n    }\n}\n\ncommit comment \"import_bgp\"\n</code></pre> <p>With this configuration, all routes received from this peer-group will be leaked into <code>FBF.inet.0</code>. However, for demonstration purposes, we\u2019ll restrict the leaking to a specific BGP prefix: 8.8.8.0/24.</p> <p>To do that, we\u2019ll use the <code>import-policy</code> feature of the rib-group. First, we define a policy to authorize leaking from <code>inet.0</code> to <code>FBF.inet.0</code>, but only for:</p> <ul> <li>direct routes, and</li> <li>the BGP prefix 8.8.8.0/24</li> </ul> <p>Here\u2019s the policy definition, followed by its application to the <code>RG_FBF</code> rib-group:</p> <pre><code>edit \nload merge terminal relative\n\npolicy-options {\n    policy-statement FBF_POLICY {\n        term LEAK_DIRECT {\n            from protocol direct;\n            then accept;\n        }\n        term LEAK_BGP {\n            from {\n                protocol bgp;\n                route-filter 8.8.8.0/24 orlonger;\n            }\n            then accept;\n        }\n        term REJECT_OTHER {\n            then reject;\n        }\n    }\n}\n\nrouting-options {\n    rib-groups {\n        RG_FBF {\n            import-rib [ inet.0 FBF.inet.0 ];\n            import-policy FBF_POLICY;         &lt;&lt;&lt; controls which routes get leaked\n        }\n    }\n}\n\ncommit comment \"add_leaking_policy\"\n</code></pre> <p>After committing, you can verify the result with:</p> <pre><code>regress@rtme-mx-62&gt; show route table FBF.inet.0 protocol bgp   \n\nFBF.inet.0: 7 destinations, 7 routes (7 active, 0 holddown, 0 hidden)\n+ = Active Route, - = Last Active, * = Both\n\n8.8.8.0/24         *[BGP/170] 01:16:31, localpref 50, from 193.252.102.2\n                      AS path: I, validation-state: unverified\n                    &gt;  to 172.16.1.1 via et-5/0/0.0, Push 20002\n</code></pre> <p>Perfect \u2014 only the 8.8.8.0/24 prefix received from the internal ASBR is installed. The primary route via the PNI isn't present in this instance and remains solely in the <code>inet.0</code> table.</p> <p>Now, to actually redirect the traffic, we\u2019ll use a simple firewall filter. It will match traffic sourced from Customer B and redirect it to the <code>FBF</code> routing instance. This filter is applied to the physical interface connected to the IP Fabric:</p> <pre><code>edit \nload merge terminal relative\n\nfirewall {\n    family inet {                       \n        filter FBF_FWD {\n            term CUSTOMER_B {\n                from {\n                    source-address {\n                        172.222.0.0/24;\n                    }\n                }\n                then {\n                    count FBF;\n                    routing-instance FBF;\n                }\n            }\n            term other {\n                then {\n                    count OTHER;\n                    accept;\n                }\n            }\n        }\n    }\n}\n\ninterfaces {\n    et-5/2/0 {\n        mtu 9200;\n        unit 0 {\n            family inet {\n                filter {\n                    input FBF_FWD;\n                }\n                address 172.16.0.4/31;\n            }\n        }\n    }\n}\n\ncommit comment \"apply_fbf\"\n</code></pre> <p>At this point, traffic should be redirected as expected:</p> <p></p> <p>To help distinguish the flows, we've configured traffic rates as follows:</p> <ul> <li>Customer A: 1000 packets per second (pps)</li> <li>Customer B: 5000 packets per second (pps)</li> </ul> <p>Let\u2019s monitor the PNI interface. As expected, only Customer A traffic goes through it (1000pps):</p> <pre><code>regress@rtme-mx-62&gt; monitor interface et-2/0/0.0   \nInterface: et-2/0/0.0, Enabled, Link is Up\n\n&lt;- truncated output -&gt;\n\nRemote statistics:\n  Input bytes:                 132708516 (0 bps)                           [0]\n  Output bytes:              49128737556 (3921056 bps)                     [0]\n  Input packets:                  270844 (0 pps)                           [0]\n  Output packets:              100262735 (1000 pps)                        [0] &lt;&lt;&lt; Only Customer A traffic\n</code></pre> <p>Now let\u2019s check the core-facing interface \u2014 we can see Customer B\u2019s traffic being redirected via FBF to the ASBR:</p> <pre><code>regress@rtme-mx-62&gt; monitor interface et-5/0/0.0  \nInterface: et-5/0/0.0, Enabled, Link is Up\n\n&lt;- truncated output -&gt;\n\nRemote statistics:\n  Input bytes:                 253750639 (584 bps)                         [0]\n  Output bytes:              57241664165 (19600072 bps)                    [0]\n  Input packets:                  533880 (1 pps)                           [0]\n  Output packets:              116839924 (5000 pps)                        [0] &lt;&lt;&lt; the tunneled Customer B traffic \n</code></pre> <p>Now, what if the iBGP session to the ASBR drops, or the 8.8.8.0/24 prefix is no longer announced?</p> <p>In that case, the route will vanish from <code>FBF.inet.0</code>, and the default reject route will take over:</p> <pre><code>regress@rtme-mx-62&gt; show route forwarding-table destination 0.0.0.0/0 table FBF \nRouting table: FBF.inet\nInternet:\nDestination        Type RtRef Next hop           Type Index    NhRef Netif\ndefault            perm     0                    rjct      520     1       &lt;&lt;&lt; default reject route\n</code></pre> <p>Just like in Case 1, traffic to 8.8.8.0/24 will be rejected and punted to the routing engine (RE), which will respond with ICMP Unreachable messages (after being HW-policed to 2k pps).</p> <p>To silently drop such packets instead of punting them, configure a static discard route as the default inside the FBF instance. But what if you want a fallback to the default routing table instead?</p> <p>That\u2019s simple. If fallback forwarding is needed, just configure a default route inside the FBF instance pointing to the <code>inet.0</code> table. If 8.8.8.0/24 disappears, traffic is then forwarded via the primary PNI path through <code>inet.0</code>.</p> <p>Here\u2019s the configuration:</p> <pre><code>edit \nload merge terminal relative\n\nrouting-instances {\n    FBF {\n        instance-type forwarding;\n        routing-options {\n            static {\n                route 0.0.0.0/0 next-table inet.0; &lt;&lt;&lt; default fallback route\n            }\n        }\n    }\n}\n\ncommit comment \"add_fallback_route\"\n</code></pre>"},{"location":"books/sample_book/main.html#pfe-analysis_1","title":"PFE analysis","text":"<p>Assuming the FBF configuration is active, let\u2019s break down how the firewall filter behaves at the PFE level. Start by listing the filter instances:</p> <pre><code>regress@rtme-mx-62&gt; start shell pfe network fpc5 \n\nroot@rtme-mx-62-fpc5:pfe&gt; show firewall instance     \nName,Index              Instance Key                    InstanceToken           LinkCount\nFBF_FWD,2                       no-next-filter-0                4777            1\n&lt;- truncated output -&gt;\n</code></pre> <p>Next, pick up the InstanceToken and resolve it using the following command:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show sandbox token 4777        \n\n&lt;- truncated output -&gt;\n\nPfe Inst:0 Hw Instance 1, type:1 op:2 ref 0\n  Counter Base:- 0x5400e8\n  Policer Base:- 0\n  Number of counters : 2 (including PSAs)\n\nterm CUSTOMER_B (pfe-inst 0)\n     Start Addr   :- 0x85fc\n     Stop Addr    :- 0x85fe\n     Stop NH      :- 0x680825491812a48c\n         Decoding :- FW_STOP: pdesc:0x104a923 desc:0x4a923\n\n     Action Addr  :- 0x4a923\n     Action NH    :- 0x812a81c00020000\n\nmatch type: prefix\n  loc: 0x85fc nh: 0x7e3000401e000000\n  FW_4BMATCH: fwop:0 desc:0x803c koffset:396 boffset:0 mask:0x149c00e8 data:0x7fb7\n\nInst: 0 Action-Type: 134\n        JNH      :- 0x2bfffffd00000300:\n                 CounterNH: Relative Base = 1, Offset = 0x0, nextNH = 0xffffff\n\nInst: 0 Action-Type: 0\n        JNH      :- 0x23fffffc0000100c:\n                 UcodeNH: Indirect Decode: Indirect, Next = 0xffffff, pnh_id = 0, ,\n\nInst: 0 Action-Type: 0\n        JNH      :- 0x20129a4c0000000c:\n                 UcodeNH: Indirect Decode: Indirect, Next = 0x4a693, pnh_id = 0, ,\n\n&lt;- truncated output -&gt;\n</code></pre> <p>Focus on the Action NH (line 17) and decode the JNH word. As shown, this represents a chain of Next-hops:</p> <p>The parameter <code>inst</code> below refers to the PFE id. </p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x812a81c00020000 inst 2     \nCallNH:desc_ptr:0x4aa07, mode=0, count=0x3\n  0x04aa04  0 : 0x2bfffffd00000300  &lt;&lt;&lt; Action Counter\n  0x04aa05  1 : 0x23fffffc0000100c  &lt;&lt;&lt; dummy action for clearing some internal states\n  0x04aa06  2 : 0x20129a4c0000000c  &lt;&lt;&lt; Action routing-instance FBF \n</code></pre> <p>Now let\u2019s analyze the third action by decoding the JNH word <code>0x20129a4c0000000c</code> - UcodeNH will execute a micro-code sequence:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x20129a4c0000000c inst 2   \nUcodeNH: Indirect Decode: Indirect, Next = 0x4a693, pnh_id = 0, ,\n</code></pre> <p>This is an indirection to a virtual address found in the Next field. To read data at <code>0x4a693</code>, use:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh vread vaddr 0x4a693 NH inst 2            \nAddr:Nexthop 0x4a693 Paddr:0x104a693, Data = 0x0812944c00020000\n</code></pre> <p>This yields two important values:</p> <ul> <li>Paddr (physical address): <code>0x104a693</code></li> <li>Data read: <code>0x0812944c00020000</code></li> </ul> <p>Note: to read a physical address, use <code>show pread paddr xxx</code>.</p> <p>Since this is a JNH word, decode it again:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x0812944c00020000 inst 2    \nCallNH:desc_ptr:0x4a513, mode=0, count=0x3\n  0x04a510  0 : 0x168c000000000000\n  0x04a511  1 : 0x08129d1c00000000\n  0x04a512  2 : 0x23fffffc00000001  &lt;&lt;&lt; this one will be skipped - related to fabric encap. \n</code></pre> <p>Now decode each action (except the third one - out of the scope of this article):</p> <ul> <li>First is a <code>ModifyNH</code> (we modify some bytes of the Local Memory - here we reset en encap len)</li> </ul> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x168c000000000000 inst 2    \nModifyNH: Subcode=Misc(26)\n(Reset encap len)\n</code></pre> <ul> <li>Second points to another JNH word <code>0x1810318100200008</code> - This one is a CallNH which means execute a list of NH in order (when <code>mode=O</code>):</li> </ul> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x08129d1c00000000 inst 2    \nCallNH:desc_ptr:0x4a747, mode=0, count=0x1\n  0x04a746  0 : 0x1810318100200008\n</code></pre> <p>Decode the first and single NH in the list, <code>0x1810318100200008</code> to reveal a KTREE structure used for route lookup:</p> <p>A KTREE is the Juniper implementation of a standard binary structure known as Patricia Tree</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x1810318100200008 inst 2    \nKtreeNH: skip=8, sw_token=0, arOffset=0, mode=1, descPtr=0xc60400, key=0x4/0 LookupKey\n</code></pre> <p>Use additional options to dump the full KTREE:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x1810318100200008 inst 2 ktree yes dump yes \nRoute                                 Depth   JNH\n------------------------------------  ------  ------------------\nDefault                                    0  0x08129df400000000\n00000000/32                                1  0x08129d4000000000\n080808/24                                  1  0x0812a04000000000  &lt;&lt;&lt; 8.8.8.0/24 entry\n&lt;- truncated output -&gt;\n</code></pre> <p>This KTREE acts as the FIB for our FBF routing-instance. For example, if traffic hits the 8.8.8.0/24 prefix, it\u2019s \"redirected\" to the action identifed by the JNH word <code>0x0812a04000000000</code> which refers to a list of NH (CallNH):</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x0812a04000000000 inst 2    \nCallNH:desc_ptr:0x4a810, mode=0, count=0x1\n  0x04a80f  0 : 0x2012a0a40000000c\n</code></pre> <p>Whose the value <code>0x2012a0a40000000c</code> refers to indirection - UcodeNH:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x2012a0a40000000c inst 2    \nUcodeNH: Indirect Decode: Indirect, Next = 0x4a829, pnh_id = 0, ,\n</code></pre> <p>To read this NH indirection at the virtual address <code>0x4a829</code>:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh vread vaddr 0x4a829 NH inst 2                               \nAddr:Nexthop 0x4a829 Paddr:0x104a829, Data = 0x0812a5fc00000000\n</code></pre> <p>One mmore time, we decode the JNH word retrieved from the previous virtual memory address - and we find out a new list of NH (CallNH):</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x0812a5fc00000000 inst 2    \nCallNH:desc_ptr:0x4a97f, mode=0, count=0x1\n  0x04a97e  0 : 0x11c0000000038d14\n</code></pre> <p>And decode <code>0x11c0000000038d14</code>:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show jnh decode word 0x11c0000000038d14 inst 2    \nModifyNH: Subcode=SetNH-Token(7),Desc=0x0,Data=0x38d14,NextNH=0\n (pfeDest:20, TokenIdMode:0/  , VC memberId:0, isReass:0, token:0x38d/909)\n</code></pre> <p>We\u2019ve reached the final forwarding result \u2014 which will set the forwarding NH index into the NH Token. Here, the token <code>0x38d</code> corresponds to the NH ID of our lookup result.</p> <p>You can get more info on this NH:</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show nh db index 0x38d \nIndex          Type        Func-Type    Proto        Nh-Flags        Ifl-Name        Ifl-Index       Nh-Token        Nh-Prefix\n909            Unicast     -            ipv4_tag     0x1             et-5/0/0.0      356             5187           ac100101/32         \n</code></pre> <p>Perfect \u2014 this matches expectations. Traffic targeting 8.8.8.0/24 via the FBF routing instance will be forwarded to the core interface <code>et-5/0/0.0</code>.</p> <p>You can dig deeper using this detailed view (to retrieve Layer 2 header information, MPLS encap...)</p> <pre><code>root@rtme-mx-62-fpc5:pfe&gt; show nh detail index 0x38d \nNexthop Info:\n\nNH Index                      : 909\nNH Type                       : Unicast\nNH Proto                      : ipv4_tag\nNH Flags                      : 0x1\nIF Name                       : et-5/0/0.0\nPrefix                        : ac100101/32\nNH Token Id                   : 5187\nNH Route Table Id             : 0\nSgid                          : 0\n\nOIF Index                     : 356\nUnderlying IFL                : .local..0 (0)\nSession Id                    : 788\nNum Tags                      : 1\nLabel                         : 0x4e22fff0 (20002)lbFlags: 0\nMTU                           : 0\nL2 Length                     : 12\nL2 Data                       : 00:00:01:64:80:00:a8:d0:e5:ef:6a:87\nFilter Index                  : 0\n\nPlatform Info\n-------------\n  FabricToken: 5193\n  EgressToken: 5192\n  IngressFeatures:\n\nContainer token: 5187\n#5 SetNhToken tokens:\n Mask : 0x0\n [  SetNhToken:5186  ]\n\n  EgressFeatures:\n\nContainer token: 5192\n#2 PushLabels tokens:\n Mask : 0x0\n [  PushLabels:5188  ]\n#4 StatsCounter tokens:\n Mask : 0x1\n [  StatsCounter:5189  ]\n#11 UcastEncap tokens:\n Mask : 0x0\n [  UcastEncap:5190  ]\n#12 SetOIF tokens:\n Mask : 0x0\n [  SetOIF:5191  ]  \n</code></pre> <p>If we repeat the exercise with the 8.8.8.0/24 prefix no longer present in the <code>FBF.inet.0</code> table, any traffic destined for 8.8.8.0/24 will match the default 0/0 route, which redirects to the <code>inet.0</code> table via a <code>next-table</code> action. In this scenario, we would notice slightly longer processing \u2014 just a few extra instructions \u2014 due to the need for two lookups:</p> <ul> <li>The first lookup occurs in the FBF FIB instance, which triggers the next-table action and redirects the processing to the main IPv4 <code>inet.0</code> table,</li> <li>The second lookup happens in the <code>inet.0</code> FIB, where the best route to 8.8.8.0/24 is selected\u2014in our case, through interface et-2/0/0.0, which connects to our PNI.</li> </ul> <p>In this situation, two KTREE structures are involved: first the <code>FBF.inet.0</code> KTREE, followed by the <code>inet.0</code> KTREE.</p> <p>The following figure provides a consolidated view of the packet traversal process and outlines the key steps of the FBF mechanism:</p> <p></p>"},{"location":"books/sample_book/main.html#conclusion","title":"Conclusion","text":"<p>In this article, we explored the mechanics of the Filter-Based Forwarding (FBF) feature, focusing on how traffic steering is implemented at the PFE level. We demonstrated two distinct approaches to configuring and validating FBF behavior. While both are effective, the second method provides greater flexibility, making it especially useful for advanced use cases.</p> <p>All tests and examples provided were conducted within the IPv4 address family, but it's important to highlight that the same FBF logic and infrastructure are fully supported for IPv6 as well, offering consistent behavior across protocol versions.</p> <p>By understanding the inner workings of FBF down to the hardware abstraction layer, network engineers can confidently design and validate sophisticated traffic steering policies.</p> <ol> <li> <p>aka. LPM\u00a0\u21a9</p> </li> </ol>"}]}